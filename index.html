<!DOCTYPE html>
<html lang="nl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Klantgesprek Transcriptie & Analyse Tool</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 900px;
            margin: 30px auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
        }
        .whatsapp-info {
            background: #e3f2fd;
            border: 2px solid #2196f3;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 25px;
            font-size: 14px;
        }
        .whatsapp-info h3 {
            margin: 0 0 15px 0;
            color: #1565c0;
        }
        .whatsapp-info ul {
            margin: 10px 0;
            padding-left: 20px;
        }
        .whatsapp-info li {
            margin-bottom: 8px;
        }
        .steps {
            display: flex;
            justify-content: space-between;
            margin-bottom: 30px;
            padding: 0 20px;
        }
        .step {
            flex: 1;
            text-align: center;
            padding: 12px;
            margin: 0 5px;
            border-radius: 5px;
            background: #e9ecef;
            color: #6c757d;
            font-weight: bold;
            font-size: 14px;
        }
        .step.active {
            background: #007cba;
            color: white;
        }
        .step.completed {
            background: #28a745;
            color: white;
        }
        .input-group {
            margin-bottom: 20px;
        }
        label {
            display: block;
            margin-bottom: 8px;
            font-weight: bold;
            color: #555;
        }
        input, select, button, textarea {
            width: 100%;
            padding: 12px;
            border: 2px solid #ddd;
            border-radius: 5px;
            font-size: 16px;
            margin-bottom: 10px;
            box-sizing: border-box;
        }
        textarea {
            min-height: 150px;
            font-family: Georgia, serif;
            line-height: 1.6;
            resize: vertical;
        }
        button {
            background: #007cba;
            color: white;
            border: none;
            cursor: pointer;
            font-weight: bold;
        }
        button:hover:not(:disabled) {
            background: #005a87;
        }
        button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        .success-btn {
            background: #28a745;
        }
        .success-btn:hover:not(:disabled) {
            background: #218838;
        }
        .secondary-btn {
            background: #6c757d;
        }
        .secondary-btn:hover:not(:disabled) {
            background: #545b62;
        }
        .record-btn {
            background: #dc3545;
        }
        .record-btn:hover:not(:disabled) {
            background: #c82333;
        }
        .record-btn.recording {
            background: #ff4757;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }
        .status {
            padding: 12px;
            margin: 15px 0;
            border-radius: 5px;
            display: none;
            font-weight: 500;
        }
        .success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        .error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        .warning {
            background: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }
        audio {
            width: 100%;
            margin: 10px 0;
        }
        .progress-bar {
            width: 100%;
            height: 20px;
            background: #e9ecef;
            border-radius: 10px;
            overflow: hidden;
            margin: 15px 0;
            display: none;
        }
        .progress-fill {
            height: 100%;
            background: #007cba;
            width: 0%;
            transition: width 0.5s ease;
        }
        .section {
            margin-bottom: 30px;
            padding: 20px;
            border: 2px solid #e9ecef;
            border-radius: 8px;
        }
        .audio-options {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
            margin-bottom: 20px;
        }
        .audio-method {
            border: 2px solid #ddd;
            padding: 20px;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s ease;
            text-align: center;
        }
        .audio-method:hover {
            border-color: #007cba;
        }
        .audio-method.selected {
            border-color: #007cba;
            background: #f8f9fa;
        }
        .audio-method h3 {
            margin: 0 0 10px 0;
            color: #333;
            font-size: 16px;
        }
        .audio-method p {
            margin: 0;
            color: #666;
            font-size: 13px;
        }
        .recording-controls {
            text-align: center;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 8px;
            margin: 15px 0;
            display: none;
        }
        .recording-timer {
            font-size: 24px;
            font-weight: bold;
            color: #dc3545;
            margin: 10px 0;
        }
        .recording-status {
            font-size: 14px;
            color: #666;
            margin-bottom: 15px;
        }
        .info-box {
            background: #e3f2fd;
            border: 1px solid #bbdefb;
            padding: 15px;
            border-radius: 5px;
            margin: 15px 0;
            font-size: 14px;
            color: #1565c0;
        }
        .btn-group {
            display: flex;
            gap: 10px;
            margin-top: 20px;
        }
        .btn-group button {
            flex: 1;
        }
        .file-upload-area {
            border: 2px dashed #ddd;
            border-radius: 8px;
            padding: 20px;
            text-align: center;
            margin: 15px 0;
            transition: all 0.3s ease;
            display: none;
        }
        .file-upload-area:hover {
            border-color: #007cba;
            background: #f8f9fa;
        }
        .file-upload-area.dragover {
            border-color: #007cba;
            background: #e3f2fd;
        }
        .custom-instruction {
            min-height: 200px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Klantgesprek Transcriptie & Analyse Tool</h1>
        
        <div class="whatsapp-info">
            <h3>üéØ Klantgesprek Analyse</h3>
            <strong>Voor WhatsApp .opus bestanden:</strong> Gebruik een van deze alternatieven:
            <ul>
                <li><strong>üì± Dictafoon App:</strong> Neem WhatsApp audio opnieuw op met je telefoon dictafoon (Voice Memos/Voice Recorder) en upload het .m4a/.mp3 bestand</li>
                <li><strong>üé§ Direct Opnemen:</strong> Gebruik de opname functie hieronder om direct je klantgesprek op te nemen</li>
                <li><strong>üîÑ Online Converter:</strong> Converteer .opus naar .mp3 via <a href="https://www.freeconvert.com/" target="_blank" style="color: #007cba; text-decoration: underline;">FreeConvert.com</a> (aanbevolen) of <a href="https://cloudconvert.com/" target="_blank" style="color: #007cba; text-decoration: underline;">CloudConvert.com</a></li>
            </ul>
        </div>
        
        <!-- Progress Steps -->
        <div class="steps">
            <div class="step active">1. Audio Upload/Opname</div>
            <div class="step">2. Transcriptie</div>
            <div class="step">3. Analyse</div>
        </div>

        <!-- Setup Section -->
        <div class="section">
            <h2>Setup</h2>
            <div class="input-group">
                <label>OpenAI API Key (voor transcriptie √©n analyse):</label>
                <input type="password" id="openaiKey" placeholder="sk-proj-... of sk-...">
                <div class="info-box" style="margin-top: 5px;">
                    Deze key wordt gebruikt voor zowel Whisper transcriptie als ChatGPT gespreksanalyse
                </div>
            </div>
            
            <div class="input-group">
                <label>Kies Audio Methode:</label>
                <div class="audio-options">
                    <div class="audio-method selected" id="uploadMethod">
                        <h3>üìÅ Bestand Uploaden</h3>
                        <p>Upload audio bestand van klantgesprek</p>
                    </div>
                    <div class="audio-method" id="recordMethod">
                        <h3>üé§ Direct Opnemen</h3>
                        <p>Neem klantgesprek direct op via browser microfoon</p>
                    </div>
                </div>
            </div>

            <!-- File Upload Area -->
            <div class="file-upload-area" id="uploadArea">
                <input type="file" id="audioFile" accept="audio/*" style="display: none;">
                <div onclick="document.getElementById('audioFile').click();" style="cursor: pointer;">
                    <div style="font-size: 48px; color: #ddd; margin-bottom: 10px;">üìÅ</div>
                    <div style="font-size: 16px; color: #666;">Klik hier of sleep een audio bestand</div>
                    <div style="font-size: 12px; color: #999; margin-top: 5px;">Ondersteund: MP3, WAV, M4A, OGG, WEBM, FLAC</div>
                </div>
            </div>

            <!-- Recording Area -->
            <div class="recording-controls" id="recordingArea">
                <div class="recording-status" id="recordingStatus">Klaar om op te nemen</div>
                <div class="recording-timer" id="recordingTimer">00:00</div>
                <div class="btn-group">
                    <button id="startRecordBtn" class="record-btn">üé§ Start Opname</button>
                    <button id="stopRecordBtn" class="secondary-btn" disabled>‚èπÔ∏è Stop Opname</button>
                    <button id="clearRecordBtn" class="secondary-btn">üóëÔ∏è Wissen</button>
                </div>
            </div>
            
            <audio id="audioPlayer" controls style="display:none;"></audio>
            
            <button id="transcribeBtn" disabled>Start Transcriptie</button>
            
            <div class="progress-bar" id="progressBar1">
                <div class="progress-fill" id="progressFill1"></div>
            </div>
            
            <div id="status1" class="status"></div>
        </div>

        <!-- Transcription Result -->
        <div class="section" id="transcriptionSection" style="display:none;">
            <h2>Transcriptie Resultaat</h2>
            <div class="info-box">
                Transcriptie voltooid! Je kunt de tekst hieronder nog bewerken voordat je de analyse laat genereren.
            </div>
            <div class="input-group">
                <label>Transcriptie (bewerkbaar):</label>
                <textarea id="transcriptionResult" placeholder="Hier verschijnt de transcriptie..."></textarea>
            </div>
        </div>

        <!-- Analysis Section -->
        <div class="section" id="analysisSection" style="display:none;">
            <h2>Gespreksanalyse</h2>
            
            <div class="input-group">
                <label>Analyse Instructies (aanpasbaar):</label>
                <textarea id="customInstruction" class="custom-instruction" placeholder="Beschrijf hier je analyse instructies...">## Taak
Analyseer dit klantgesprek en maak een samenvatting met sprekers herkenning.

## Sprekers Herkenning
- Zoek naar namen die in het gesprek worden genoemd
- Identificeer spreekpatronen per persoon (vraagsteller vs antwoorder)
- Let op rolverdelingen (klant vs adviseur/verkoper)
- Als geen namen duidelijk zijn, gebruik Spreker A/B met rolomschrijving

## Output Format
**GESPREKSANALYSE**

**SPREKERS:**
- [Naam/Rol]: [korte karakterisering gebaseerd op gespreksrol]
- [Naam/Rol]: [korte karakterisering gebaseerd op gespreksrol]

**HOOFDPUNTEN:**
- [Belangrijkste besproken onderwerpen per thema]

**ACTIEPUNTEN:**
- Voor [Naam]: [specifieke taken/toezeggingen]
- Voor [Naam]: [specifieke taken/toezeggingen]

**AFSPRAKEN & DEADLINES:**
- [Concrete vervolgstappen met wie en wanneer]

## Richtlijnen
- Gebruik daadwerkelijke namen uit gesprek waar mogelijk
- Bij onduidelijkheid: geef logische rolverdeling (Klant/Adviseur)
- Focus op concrete, actionable uitkomsten
- Houd het bondig maar volledig</textarea>
            </div>
            
            <button id="generateFeedbackBtn" class="success-btn" disabled>Genereer Analyse</button>
            
            <div class="progress-bar" id="progressBar2">
                <div class="progress-fill" id="progressFill2"></div>
            </div>
            
            <div id="status2" class="status"></div>
        </div>

        <!-- Analysis Result -->
        <div class="section" id="feedbackSection" style="display:none;">
            <h2>Analyse Resultaat</h2>
            <div class="input-group">
                <label>Gegenereerde Gespreksanalyse:</label>
                <textarea id="feedbackResult" readonly></textarea>
            </div>
            
            <div class="btn-group">
                <button id="newFeedbackBtn" class="secondary-btn">Nieuwe Analyse (behoud audio)</button>
                <button id="restartBtn" class="secondary-btn">Herstart (wis alles)</button>
                <button id="exportBtn" class="success-btn">Download Bestanden</button>
            </div>
        </div>
    </div>

    <script>
        // Global variables
        let audioData = null;
        let currentStep = 1;
        let audioMethod = 'upload';
        let mediaRecorder = null;
        let recordingChunks = [];
        let recordingTimer = null;
        let recordingStartTime = 0;

        // Initialize app
        document.addEventListener('DOMContentLoaded', function() {
            loadSavedKeys();
            setupEventListeners();
            selectAudioMethod('upload');
        });
        
        function loadSavedKeys() {
            const openaiKey = localStorage.getItem('openai_api_key');
            
            if (openaiKey) document.getElementById('openaiKey').value = openaiKey;
            
            validateInputs();
        }
        
        function setupEventListeners() {
            // Input validation
            document.getElementById('openaiKey').addEventListener('input', validateInputs);
            document.getElementById('audioFile').addEventListener('change', handleFileUpload);
            
            // Audio method selection
            document.getElementById('uploadMethod').addEventListener('click', () => selectAudioMethod('upload'));
            document.getElementById('recordMethod').addEventListener('click', () => selectAudioMethod('record'));
            
            // Recording controls
            document.getElementById('startRecordBtn').addEventListener('click', startRecording);
            document.getElementById('stopRecordBtn').addEventListener('click', stopRecording);
            document.getElementById('clearRecordBtn').addEventListener('click', clearRecording);
            
            // Main actions
            document.getElementById('transcribeBtn').addEventListener('click', startTranscription);
            document.getElementById('generateFeedbackBtn').addEventListener('click', generateFeedback);
            
            // Control buttons
            document.getElementById('newFeedbackBtn').addEventListener('click', newFeedback);
            document.getElementById('restartBtn').addEventListener('click', restartTool);
            document.getElementById('exportBtn').addEventListener('click', exportReport);
            
            // Text input validation
            document.getElementById('customInstruction').addEventListener('input', validateFeedbackGeneration);
            document.getElementById('transcriptionResult').addEventListener('input', validateFeedbackGeneration);
            
            // Drag and drop for file upload
            const uploadArea = document.getElementById('uploadArea');
            uploadArea.addEventListener('dragover', handleDragOver);
            uploadArea.addEventListener('dragleave', handleDragLeave);
            uploadArea.addEventListener('drop', handleDrop);
        }
        
        function selectAudioMethod(method) {
            audioMethod = method;
            
            // Update UI
            document.getElementById('uploadMethod').classList.toggle('selected', method === 'upload');
            document.getElementById('recordMethod').classList.toggle('selected', method === 'record');
            
            // Show/hide appropriate areas
            document.getElementById('uploadArea').style.display = method === 'upload' ? 'block' : 'none';
            document.getElementById('recordingArea').style.display = method === 'record' ? 'block' : 'none';
            
            // Clear previous audio data when switching methods
            if (audioData) {
                audioData = null;
                document.getElementById('audioPlayer').style.display = 'none';
                document.getElementById('audioFile').value = '';
                validateInputs();
            }
        }
        
        function validateInputs() {
            const openaiKey = document.getElementById('openaiKey').value;
            const hasAudio = audioData !== null;
            
            document.getElementById('transcribeBtn').disabled = !openaiKey || !hasAudio;
        }
        
        function validateFeedbackGeneration() {
            const transcription = document.getElementById('transcriptionResult').value.trim();
            const instruction = document.getElementById('customInstruction').value.trim();
            
            document.getElementById('generateFeedbackBtn').disabled = !transcription || !instruction;
        }
        
        // File upload handlers
        function handleDragOver(event) {
            event.preventDefault();
            document.getElementById('uploadArea').classList.add('dragover');
        }
        
        function handleDragLeave(event) {
            event.preventDefault();
            document.getElementById('uploadArea').classList.remove('dragover');
        }
        
        function handleDrop(event) {
            event.preventDefault();
            document.getElementById('uploadArea').classList.remove('dragover');
            
            const files = event.dataTransfer.files;
            if (files.length > 0) {
                const file = files[0];
                // Simulate file input change
                const fileInput = document.getElementById('audioFile');
                const dataTransfer = new DataTransfer();
                dataTransfer.items.add(file);
                fileInput.files = dataTransfer.files;
                handleFileUpload({ target: fileInput });
            }
        }
        
        function handleFileUpload(event) {
            const file = event.target.files[0];
            if (!file) {
                audioData = null;
                validateInputs();
                return;
            }
            
            // Check file size (25MB limit)
            if (file.size > 25 * 1024 * 1024) {
                showStatus('Bestand te groot. Maximum 25MB toegestaan.', 'error', 1);
                return;
            }
            
            // Check file type
            const extension = file.name.toLowerCase().split('.').pop();
            const supportedFormats = ['mp3', 'wav', 'm4a', 'ogg', 'webm', 'flac'];
            
            if (!supportedFormats.includes(extension)) {
                showStatus('Niet ondersteund formaat. Gebruik: MP3, WAV, M4A, OGG, WEBM of FLAC.', 'error', 1);
                return;
            }
            
            audioData = file;
            
            // Show audio player
            const audioPlayer = document.getElementById('audioPlayer');
            audioPlayer.src = URL.createObjectURL(file);
            audioPlayer.style.display = 'block';
            
            const sizeInMB = (file.size / 1024 / 1024).toFixed(1);
            showStatus(`Audio geladen: ${file.name} (${sizeInMB}MB)`, 'success', 1);
            
            validateInputs();
        }
        
        // Recording functions
        async function startRecording() {
            try {
                // Request microphone access
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Initialize MediaRecorder
                mediaRecorder = new MediaRecorder(stream);
                recordingChunks = [];
                
                mediaRecorder.ondataavailable = function(event) {
                    if (event.data.size > 0) {
                        recordingChunks.push(event.data);
                    }
                };
                
mediaRecorder.onstop = function() {
    // Create audio blob
    const audioBlob = new Blob(recordingChunks, { type: 'audio/webm' });
    
    // Create file from blob
    const timestamp = new Date().toISOString().slice(0, 19).replace(/[-:]/g, '');
    audioData = new File([audioBlob], `klantgesprek_${timestamp}.webm`, { type: 'audio/webm' });
    
    // Automatisch downloaden
    const downloadUrl = URL.createObjectURL(audioBlob);
    const downloadLink = document.createElement('a');
    downloadLink.href = downloadUrl;
    downloadLink.download = `klantgesprek_${timestamp}.webm`;
    document.body.appendChild(downloadLink);
    downloadLink.click();
    document.body.removeChild(downloadLink);
    URL.revokeObjectURL(downloadUrl);
    
    // Show audio player
    const audioPlayer = document.getElementById('audioPlayer');
    audioPlayer.src = URL.createObjectURL(audioBlob);
    audioPlayer.style.display = 'block';
    
    const sizeInMB = (audioData.size / 1024 / 1024).toFixed(1);
    showStatus(`Opname voltooid en gedownload! (${sizeInMB}MB)`, 'success', 1);
    
    // Stop all tracks
    stream.getTracks().forEach(track => track.stop());
    
    validateInputs();
};
                
                // Start recording
                mediaRecorder.start();
                recordingStartTime = Date.now();
                
                // Update UI
                document.getElementById('startRecordBtn').disabled = true;
                document.getElementById('startRecordBtn').classList.add('recording');
                document.getElementById('stopRecordBtn').disabled = false;
                document.getElementById('recordingStatus').textContent = 'üî¥ Opname actief...';
                
                // Start timer
                recordingTimer = setInterval(updateRecordingTimer, 1000);
                
                showStatus('Opname gestart! Spreek nu in je microfoon.', 'success', 1);
                
            } catch (error) {
                console.error('Recording error:', error);
                showStatus('Kan geen toegang krijgen tot microfoon. Controleer je browser instellingen.', 'error', 1);
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                
                // Update UI
                document.getElementById('startRecordBtn').disabled = false;
                document.getElementById('startRecordBtn').classList.remove('recording');
                document.getElementById('stopRecordBtn').disabled = true;
                document.getElementById('recordingStatus').textContent = 'Opname gestopt';
                
                // Stop timer
                if (recordingTimer) {
                    clearInterval(recordingTimer);
                    recordingTimer = null;
                }
            }
        }
        
        function clearRecording() {
            // Stop recording if active
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                stopRecording();
            }
            
            // Clear data
            audioData = null;
            recordingChunks = [];
            
            // Reset UI
            document.getElementById('audioPlayer').style.display = 'none';
            document.getElementById('recordingTimer').textContent = '00:00';
            document.getElementById('recordingStatus').textContent = 'Klaar om op te nemen';
            
            validateInputs();
            showStatus('Opname gewist', 'warning', 1);
        }
        
        function updateRecordingTimer() {
            const elapsed = Math.floor((Date.now() - recordingStartTime) / 1000);
            const minutes = Math.floor(elapsed / 60);
            const seconds = elapsed % 60;
            document.getElementById('recordingTimer').textContent = 
                `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
        }
        
        async function startTranscription() {
            const openaiKey = document.getElementById('openaiKey').value;
            
            if (!audioData || !openaiKey) return;
            
            // Update UI
            setButtonState('transcribeBtn', true);
            updateSteps(2);
            showProgress(1, 25);
            showStatus('Audio wordt verstuurd naar OpenAI Whisper...', 'success', 1);
            
            try {
                // Prepare form data
                const formData = new FormData();
                formData.append('file', audioData);
                formData.append('model', 'whisper-1');
                formData.append('language', 'nl');
                
                showProgress(1, 50);
                
                // Make API call
                const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${openaiKey}`
                    },
                    body: formData
                });
                
                showProgress(1, 75);
                
                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`OpenAI API error (${response.status}): ${errorText}`);
                }
                
                const result = await response.json();
                
                if (!result.text) {
                    throw new Error('Geen transcriptie ontvangen van OpenAI');
                }
                
                // Show results
                document.getElementById('transcriptionResult').value = result.text;
                document.getElementById('transcriptionSection').style.display = 'block';
                document.getElementById('analysisSection').style.display = 'block';
                
                showProgress(1, 100);
                showStatus('Transcriptie voltooid! Scroll naar beneden voor gespreksanalyse.', 'success', 1);
                
                // Save API key
                localStorage.setItem('openai_api_key', openaiKey);
                
                // Auto-resize textarea
                autoResizeTextarea(document.getElementById('transcriptionResult'));
                validateFeedbackGeneration();
                
                setTimeout(() => {
                    hideProgress(1);
                    updateSteps(3);
                }, 2000);
                
            } catch (error) {
                console.error('Transcription error:', error);
                showStatus(`Fout: ${error.message}`, 'error', 1);
                hideProgress(1);
                updateSteps(1);
            } finally {
                setButtonState('transcribeBtn', false);
            }
        }
        
        async function generateFeedback() {
            const openaiKey = document.getElementById('openaiKey').value;
            const transcription = document.getElementById('transcriptionResult').value.trim();
            const instruction = document.getElementById('customInstruction').value.trim();
            
            if (!openaiKey || !transcription || !instruction) return;
            
            // Update UI
            setButtonState('generateFeedbackBtn', true);
            showProgress(2, 25);
            showStatus('ChatGPT analyseert het klantgesprek...', 'success', 2);
            
            try {
                const prompt = `${instruction}

---

Hieronder is de transcriptie van het klantgesprek dat geanalyseerd moet worden:

${transcription}

Geef je gedetailleerde analyse volgens de bovenstaande instructies.`;
                
                showProgress(2, 50);
                
                // Make ChatGPT API call
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${openaiKey}`,
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        model: 'gpt-4-turbo',
                        messages: [
                            { 
                                role: 'user', 
                                content: prompt 
                            }
                        ],
                        max_tokens: 4000,
                        temperature: 0.3
                    })
                });
                
                showProgress(2, 75);
                
                if (!response.ok) {
                    const errorText = await response.text();
                    console.error('ChatGPT API Error:', errorText);
                    throw new Error(`ChatGPT API error (${response.status}): ${errorText}`);
                }
                
                const result = await response.json();
                
                if (!result.choices || !result.choices[0] || !result.choices[0].message || !result.choices[0].message.content) {
                    throw new Error('Geen analyse ontvangen van ChatGPT');
                }
                
                const feedback = result.choices[0].message.content;
                
                // Show results
                document.getElementById('feedbackResult').value = feedback;
                document.getElementById('feedbackSection').style.display = 'block';
                
                showProgress(2, 100);
                showStatus('Analyse gegenereerd! Scroll naar beneden voor het resultaat.', 'success', 2);
                
                // Auto-resize textarea
                autoResizeTextarea(document.getElementById('feedbackResult'));
                
                setTimeout(() => {
                    hideProgress(2);
                    // Scroll to results
                    document.getElementById('feedbackSection').scrollIntoView({ 
                        behavior: 'smooth', 
                        block: 'start' 
                    });
                }, 2000);
                
            } catch (error) {
                console.error('Analysis generation error:', error);
                showStatus(`Fout: ${error.message}`, 'error', 2);
                hideProgress(2);
            } finally {
                setButtonState('generateFeedbackBtn', false);
            }
        }
        
        function newFeedback() {
            // Reset feedback section
            document.getElementById('feedbackResult').value = '';
            document.getElementById('feedbackSection').style.display = 'none';
            
            // Re-validate
            validateFeedbackGeneration();
            
            // Scroll to analysis section
            document.getElementById('analysisSection').scrollIntoView({ 
                behavior: 'smooth', 
                block: 'start' 
            });
        }
        
        function restartTool() {
            // Stop any active recording
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                stopRecording();
            }
            
            // Clear recording timer
            if (recordingTimer) {
                clearInterval(recordingTimer);
                recordingTimer = null;
            }
            
            // Reset all data
            audioData = null;
            recordingChunks = [];
            document.getElementById('audioFile').value = '';
            document.getElementById('audioPlayer').style.display = 'none';
            document.getElementById('transcriptionResult').value = '';
            document.getElementById('feedbackResult').value = '';
            
            // Reset recording UI
            document.getElementById('recordingTimer').textContent = '00:00';
            document.getElementById('recordingStatus').textContent = 'Klaar om op te nemen';
            document.getElementById('startRecordBtn').disabled = false;
            document.getElementById('startRecordBtn').classList.remove('recording');
            document.getElementById('stopRecordBtn').disabled = true;
            
            // Hide sections
            document.getElementById('transcriptionSection').style.display = 'none';
            document.getElementById('analysisSection').style.display = 'none';
            document.getElementById('feedbackSection').style.display = 'none';
            
            // Reset progress and status
            hideProgress(1);
            hideProgress(2);
            document.getElementById('status1').style.display = 'none';
            document.getElementById('status2').style.display = 'none';
            
            // Reset steps
            updateSteps(1);
            
            // Reset selections
            selectAudioMethod('upload');
            
            // Re-validate
            validateInputs();
            
            // Scroll to top
            window.scrollTo({ top: 0, behavior: 'smooth' });
        }
        
        function exportReport() {
            const transcription = document.getElementById('transcriptionResult').value;
            const report = document.getElementById('feedbackResult').value;
            const timestamp = new Date().toISOString().slice(0, 10);
            
            if (!transcription || !report) {
                showStatus('Geen data om te exporteren', 'error', 2);
                return;
            }
            
            // Export 1: Transcriptie
            const transcriptBlob = new Blob([transcription], { type: 'text/plain;charset=utf-8' });
            const transcriptUrl = URL.createObjectURL(transcriptBlob);
            
            const transcriptLink = document.createElement('a');
            transcriptLink.href = transcriptUrl;
            transcriptLink.download = `Klantgesprek_Transcriptie_${timestamp}.txt`;
            document.body.appendChild(transcriptLink);
            transcriptLink.click();
            document.body.removeChild(transcriptLink);
            URL.revokeObjectURL(transcriptUrl);
            
            // Export 2: Analyse (small delay to avoid browser blocking)
            setTimeout(() => {
                const reportBlob = new Blob([report], { type: 'text/plain;charset=utf-8' });
                const reportUrl = URL.createObjectURL(reportBlob);
                
                const reportLink = document.createElement('a');
                reportLink.href = reportUrl;
                reportLink.download = `Klantgesprek_Analyse_${timestamp}.txt`;
                document.body.appendChild(reportLink);
                reportLink.click();
                document.body.removeChild(reportLink);
                URL.revokeObjectURL(reportUrl);
                
                showStatus('Beide bestanden ge√´xporteerd: transcriptie en analyse!', 'success', 2);
            }, 500);
        }
        
        // Utility functions
        function showStatus(message, type, step) {
            const status = document.getElementById(`status${step}`);
            status.textContent = message;
            status.className = `status ${type}`;
            status.style.display = 'block';
            
            if (type === 'success') {
                setTimeout(() => {
                    if (status.textContent === message) {
                        status.style.display = 'none';
                    }
                }, 5000);
            }
        }
        
        function showProgress(step, percentage) {
            const progressBar = document.getElementById(`progressBar${step}`);
            const progressFill = document.getElementById(`progressFill${step}`);
            
            progressBar.style.display = 'block';
            progressFill.style.width = `${percentage}%`;
        }
        
        function hideProgress(step) {
            const progressBar = document.getElementById(`progressBar${step}`);
            progressBar.style.display = 'none';
            document.getElementById(`progressFill${step}`).style.width = '0%';
        }
        
        function setButtonState(buttonId, disabled) {
            document.getElementById(buttonId).disabled = disabled;
        }
        
        function updateSteps(activeStep) {
            const steps = document.querySelectorAll('.step');
            steps.forEach((step, index) => {
                const stepNumber = index + 1;
                step.classList.remove('active', 'completed');
                
                if (stepNumber < activeStep) {
                    step.classList.add('completed');
                } else if (stepNumber === activeStep) {
                    step.classList.add('active');
                }
            });
        }
        
        function autoResizeTextarea(textarea) {
            textarea.style.height = 'auto';
            textarea.style.height = Math.max(textarea.scrollHeight, 150) + 'px';
        }
        
        // Auto-resize textareas on input
        document.addEventListener('input', function(e) {
            if (e.target.tagName === 'TEXTAREA') {
                autoResizeTextarea(e.target);
            }
        });
    </script>
</body>
</html>
